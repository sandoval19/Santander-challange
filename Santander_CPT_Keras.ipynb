{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santander_CPT_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandoval19/Santander-challange/blob/master/Santander_CPT_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKWN40kqT5lM",
        "colab_type": "text"
      },
      "source": [
        "Import the packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxDC_u5CGDea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow import keras\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToshPbvdUDLn",
        "colab_type": "text"
      },
      "source": [
        "Check if everything is okay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ah2nnjhPDoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_correct_tf_version = '1.14.' in tf.__version__\n",
        "assert is_correct_tf_version, \"Wrong tensorflow version {} installed\".format(tf.__version__)\n",
        "\n",
        "is_eager_enabled = tf.executing_eagerly()\n",
        "assert is_eager_enabled,      \"Tensorflow eager mode is not enabled\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKFcEFGVmHi",
        "colab_type": "text"
      },
      "source": [
        "#Analisis de los datos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axutW8s_Vkxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "print(\"dimensiones del train set:{}, test set:{}\".format(train_data.shape,test_data.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk42QjUHT31w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def missing_data(data):\n",
        "\t\"\"\"\n",
        "\tAnalyze the data, which its type is dataFrame to look for missing total values\n",
        "\tinput: dataFrame \n",
        "\toutput: if not: Boolean, if there is missing data: dataFrame with missing values per colums\n",
        "\t\"\"\"\n",
        "\tflag = data.isna().sum().any()\n",
        "\tif flag:\n",
        "\t\tnull_data=data.isnull().sum()\n",
        "\t\tpercent= (null_data/data.isnull().count())*100\n",
        "\n",
        "\t\t#new data frame to return \n",
        "\t\tmis_data= pd.concat([null_data,percent],axis=1,keys=['Total','Percent'])\n",
        "\t\tcolumns_type=[]\n",
        "\t\tfor col in data.columns:\n",
        "\t\t\tdtype= str(data[col].dtype)\n",
        "\t\t\tcolumns_type.append(dtype)\n",
        "\t\tmis_data['Type'] = columns_type\n",
        "\t\treturn (np.transpose(mis_data))\n",
        "\telse:\n",
        "\t\treturn(False)\n",
        "\n",
        "df_count_train=(missing_data(train_data))\n",
        "print(df_count_train)\n",
        "df_count_test=(missing_data(test_data))\n",
        "print(df_count_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQV3T9w9VzXa",
        "colab_type": "text"
      },
      "source": [
        "Se puede observar para cada feature no hay valores perdidos\n",
        "\n",
        "Ahora se analizan algunos valores estadisticos de los data set: total, mean, std, min, percentils."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l5ZLdnPV5LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_data.describe()\n",
        "print(train_stats)\n",
        "test_stats = test_data.describe()\n",
        "print(test_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfMi6kqyWDj4",
        "colab_type": "text"
      },
      "source": [
        "**Al ver la desviación estander y mean se puede inferir que los features (columnas) no estan normalizados: diferentes std y mean para cada feature.**\n",
        "\n",
        "**Tampoco escalados: rangos de min-max considerables para cada feature.\n",
        "Se considera hacer escalamiento, normalización/estandarización**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4fm6gSDWxYi",
        "colab_type": "text"
      },
      "source": [
        "Se Analiza la distribución de datos para ambos casos target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gUKslKYWqnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(train_data['target'],palette='Set2')\n",
        "plt.show()\n",
        "\n",
        "#pandas acomoda de manera descendente la predominancia\n",
        "print( train_data[\"target\"].value_counts())\n",
        "print(\"There are {}% target values with 1\".format(100 * train_data[\"target\"].value_counts()[1]/train_data.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nwjvO8TW8-K",
        "colab_type": "text"
      },
      "source": [
        "Se muestrea el set de train para generar un data set mas parejo en clases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq9syuulXc8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ones = train_data[train_data['target'] > 0]\n",
        "print(\"Shape of Clase One's\",df_ones.shape)\n",
        "#se toman un 15% de la clase 1 \n",
        "fracc=0.15\n",
        "df_zeros = train_data[train_data['target'] == 0].sample(frac=fracc)\n",
        "print(\"Shape {} of Clase Zero's with: {} '%' of the original set\".format(df_zeros.shape,fracc))\n",
        "#we concat both to the sampling dataframe\n",
        "#if frac is used with value 1 it will return all the data but shuffled\n",
        "train_data = pd.concat([df_ones, df_zeros]).sample(frac=1) #shuffling\n",
        "test_data= test_data.sample(n=train_data.shape[0])\n",
        "print(\"Shape of the new data sampled:\",train_data.shape)\n",
        "print(\"Shape of the new test_data: \", test_data.shape)\n",
        "print(train_data.head())\n",
        "print(train_data.tail())\n",
        "\n",
        "sns.countplot(train_data['target'],palette='Set2')\n",
        "plt.title('New data distribution after regroup')\n",
        "plt.show()\n",
        "print( train_data[\"target\"].value_counts())\n",
        "\n",
        "print(\"There are {}% target values with 1\".format(100 * train_data[\"target\"].value_counts()[1]/train_data.shape[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_yo0AKYIW3",
        "colab_type": "text"
      },
      "source": [
        "Se analiza la distribución normal de las features(columns) para los dos casos de target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJPeqLhYJUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_feature_distribution(df1, df2, label1, label2, features):\n",
        "    \"\"\"\n",
        "    Grafica la probabilidad de la funcion de densidad (PDF) para ambos dataframes \n",
        "    basado en que las features estan en ambos dataframes y las etiqueta dependiendo del label\n",
        "    input: dataframe1, dataframe2, string:label 1, string:label 2,lista/serie:features\n",
        "    output: Nan\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(10,10,figsize=(22,22))\n",
        "    for feature in features:\n",
        "        i += 1\n",
        "        plt.subplot(10,10,i)\n",
        "        sns.distplot(df1[feature], hist=False,label=label1)\n",
        "        sns.distplot(df2[feature], hist=False,label=label2)\n",
        "        plt.xlabel(feature, fontsize=9)\n",
        "        locs, labels = plt.xticks()\n",
        "        plt.tick_params(axis='x', which='major', labelsize=6)\n",
        "        plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "    plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztydO_AtbDvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#primeros 100 features\n",
        "t0 = train_data.loc[train_data['target'] == 0]\n",
        "t1 = train_data.loc[train_data['target'] == 1]\n",
        "features1 = train_data.columns.values[2:102]\n",
        "print(len(features1))\n",
        "plot_feature_distribution(t0, t1, '0', '1', features1)\n",
        "#los 100 features restantes\n",
        "features2 = train_data.columns.values[102:202]\n",
        "plot_feature_distribution(t0, t1, '0', '1', features2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpJTDaYRbNFN",
        "colab_type": "text"
      },
      "source": [
        "**Se analizar si entre los dos target alguna feature se diferencia mucho entre 1 y 0,\n",
        "puede ser un factor importante que el modelo aprenda a diferenciar entre las dos clases.\n",
        "Así también como features que sean muy similares, brindarían poca información para diferencias las clases**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV5ewb3SbwUT",
        "colab_type": "text"
      },
      "source": [
        "Ahora se analiza la distribución de las features(columns) para los set de train y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9JJsdTVbHU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature_distribution(train_data,test_data,'train','test',features1)\n",
        "plot_feature_distribution(train_data,test_data,'train','test',features2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9eVMMuHb0ax",
        "colab_type": "text"
      },
      "source": [
        "**Se puede analizar que entre train y test algunas features o son similares en distribución,\n",
        "o son muy distintas.\n",
        "Esto puede llevar a un criterio de selccion de features, ya que al ser distintas en train y test\n",
        "el modelo aprendera un comportamiento para esa feature que nunca va a ver en el test, así clasificando \n",
        "de manera erronea.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl_q-ImsYNVO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}